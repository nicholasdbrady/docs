---
title: 'Quickstart'
description: 'Get started with Azure AI Foundry'
icon: 'rocket'
---

## Setup your development

Learn how to update your docs locally and deploy them to the public.

### Edit and preview

<AccordionGroup>
  <Accordion icon="github" title="Clone your docs locally">
    During the onboarding process, we created a repository on your Github with
    your docs content. You can find this repository on our
    [dashboard](https://dashboard.mintlify.com). To clone the repository
    locally, follow these
    [instructions](https://docs.github.com/en/repositories/creating-and-managing-repositories/cloning-a-repository)
    in your terminal.
  </Accordion>
  <Accordion icon="rectangle-terminal" title="Preview changes">
    Previewing helps you make sure your changes look as intended. We built a
    command line interface to render these changes locally. 
    1. Install the
    [Mintlify CLI](https://www.npmjs.com/package/mintlify) to preview the
    documentation changes locally with this command: ``` npm i -g mintlify ```
    2. Run the following command at the root of your documentation (where
    `docs.json` is): ``` mintlify dev ```
    <Note>
      If youâ€™re currently using the legacy ```mint.json``` configuration file, please update the Mintlify CLI:


      ```npm i -g mintlify@latest```
      And run the new upgrade command in your docs repository:

      ```mintlify upgrade```
      You should now be using the new ```docs.json``` configuration file. Feel free to delete the ```mint.json``` file from your repository.
    </Note>
  </Accordion>
</AccordionGroup>

### Deploy your changes

<AccordionGroup>

<Accordion icon="message-bot" title="Install our Github app">
  Our Github app automatically deploys your changes to your docs site, so you
  don't need to manage deployments yourself. You can find the link to install on
  your [dashboard](https://dashboard.mintlify.com). Once the bot has been
  successfully installed, there should be a check mark next to the commit hash
  of the repo.
</Accordion>
<Accordion icon="rocket" title="Push your changes">
  [Commit and push your changes to
  Git](https://docs.github.com/en/get-started/using-git/pushing-commits-to-a-remote-repository#about-git-push)
  for your changes to update in your docs site. If you push and don't see that
  the Github app successfully deployed your changes, you can also manually
  update your docs through our [dashboard](https://dashboard.mintlify.com).
</Accordion>

</AccordionGroup>

## Update your docs

Add content directly in your files with MDX syntax and React components. You can use any of our components, or even build your own.

<CardGroup>

<Card title="Add Content With MDX" icon="file" href="/essentials/markdown">
  Add content to your docs with MDX syntax.
</Card>

<Card
  title="Add Code Blocks"
  icon="square-code"
  href="/essentials/code"
>
  Add code directly to your docs with syntax highlighting.
</Card>

<Card
  title="Add Images"
  icon="image"
  href="/essentials/images"
>
  Add images to your docs to make them more engaging.
</Card>

<Card
  title="Add Custom Components"
  icon="puzzle-piece"
  href="/essentials/reusable-snippets"
>
  Add templates to your docs to make them more reusable.
</Card>

</CardGroup>

# Quickstart: Get started with Azure AI Foundry

In this quickstart, we walk you through setting up your local development environment with the [Azure AI Foundry](https://ai.azure.com/?cid=learnDocs) SDK. We write a prompt, run it as part of your app code, trace the LLM calls being made, and run a basic evaluation on the outputs of the LLM.

<Note>
The rest of this article shows how to use a **[!INCLUDE [hub](../includes/hub-project-name.md)]**.  Select **[!INCLUDE [fdp](../includes/fdp-project-name.md)]** at the top of this article if you want to use a [!INCLUDE [fdp](../includes/fdp-project-name.md)] instead.  [Which type of project do I need?](../what-is-azure-ai-foundry.md#which-type-of-project-do-i-need)
</Note>

## Prerequisites

- An [Azure subscription](https://azure.microsoft.com/free/). If you don't have an Azure subscription, create a free account before you begin.
- A [!INCLUDE [hub-project-name](../includes/hub-project-name.md)]. If you're new to Azure AI Foundry and don't have a [!INCLUDE [hub-project-name](../includes/hub-project-name.md)], select **[!INCLUDE [fdp](../includes/fdp-project-name.md)]** at the top of this article to use a [!INCLUDE [fdp-project-name](../includes/fdp-project-name.md)] instead.

## Set up your development environment

1. [Set up your development environment](../how-to/develop/install-cli-sdk.md?pivots=programming-language-python)

1. Install these packages.

    ```bash
    pip install azure-ai-inference azure-identity azure-ai-projects==1.0.0b10
    ```

    > [!NOTE]
    > Different project types require different versions of the `azure-ai-projects` package. To avoid conflicts, create separate Python environments: use version `1.0.0b10` for [!INCLUDE [hub-project-name](../includes/hub-project-name.md)]s and the latest version for [!INCLUDE [fdp-project-name](../includes/fdp-project-name.md)]s.

## Deploy a model

[!INCLUDE [tip-left-pane](../includes/tip-left-pane.md)]

1. Sign in to [Azure AI Foundry](https://ai.azure.com/?cid=learnDocs).
1. Select a [!INCLUDE [hub-project-name](../includes/hub-project-name.md)]. If you don't have a [!INCLUDE [hub-project-name](../includes/hub-project-name.md)], select **[!INCLUDE [fdp](../includes/fdp-project-name.md)]** at the top of this article to use a [!INCLUDE [fdp-project-name](../includes/fdp-project-name.md)] instead.

1. Select **Model catalog** from the left pane.

1. Select the **gpt-4o-mini** model from the list of models. You can use the search bar to find it. 

1. On the model details page, select **Deploy**.

    :::image type="content" source="../media/tutorials/chat/deploy-model.png" alt-text="Screenshot of the model details page with a button to deploy the model." lightbox="../media/tutorials/chat/deploy-model.png":::


1. Leave the default **Deployment name**. Select **Deploy**.

1. Once the model is deployed, select **Open in playground** to test your model.

## Build your chat app

Create a file named **chat.py**.  Copy and paste the following code into it.

:::code language="python" source="~/azureai-samples-main/scenarios/projects/basic/chat-simple.py":::

## Insert your connection string

Your project connection string is required to call the Azure OpenAI in Azure AI Foundry Models from your code. 

Find your connection string in the Azure AI Foundry project you created in the [Azure AI Foundry playground quickstart](../quickstarts/get-started-playground.md).  Open the project, then find the connection string on the **Overview** page.  

:::image type="content" source="../media/quickstarts/azure-ai-sdk/connection-string.png" alt-text="Screenshot shows the overview page of a project and the location of the connection string.":::

Copy the connection string and replace `<your-connection-string-goes-here>` in the **chat.py** file.

## Run your chat script

Run the script to see the response from the model.

```bash
python chat.py
```

## Generate prompt from user input and a prompt template

The script uses hardcoded input and output messages. In a real app you'd take input from a client application, generate a system message with internal instructions to the model, and then call the LLM with all of the messages.

Let's change the script to take input from a client application and generate a system message using a prompt template.

1. Remove the last line of the script that prints a response.

1. Now define a `get_chat_response` function that takes messages and context, generates a system message using a prompt template, and calls a model.  Add this code to your  existing **chat.py** file:

    :::code language="python" source="~/azureai-samples-main/scenarios/projects/basic/chat-template.py" id="chat_function":::

    > [!NOTE]
    > The prompt template uses mustache format.

    The get_chat_response function could be easily added as a route to a FastAPI or Flask app to enable calling this function from a front-end web application.

1. Now simulate passing information from a frontend application to this function.  Add the following code to the end of your **chat.py** file.  Feel free to play with the message and add your own name.

    :::code language="python" source="~/azureai-samples-main/scenarios/projects/basic/chat-template.py" id="create_response":::

Run the revised script to see the response from the model with this new input.

```bash
python chat.py
```

## Clean up resources

[!INCLUDE [clean-up-resources](../includes/clean-up-resources.md)]

## Next step

> [!div class="nextstepaction"]
> [Add data and use retrieval augmented generation (RAG) to build a custom chat app](../tutorials/copilot-sdk-create-resources.md)

::: zone-end

::: zone pivot="fdp-project"

[!INCLUDE [get-started-fdp](../includes/get-started-fdp.md)]

::: zone-end